{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "collected-executive",
   "metadata": {},
   "source": [
    "# Analyze sea-level predictions for Greenland by ISMIP6 and Aschwanden et al (2019) [AS19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-bargain",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "republican-hunter",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_ismip6' from 'utilities.data_loader' (/Volumes/zachariae/ismip6-ipcc/utilities/data_loader.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4da7a8e57ab1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_imbie\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_mouginot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_grace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_ismip6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhist_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproj_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproj_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecpera\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'load_ismip6' from 'utilities.data_loader' (/Volumes/zachariae/ismip6-ipcc/utilities/data_loader.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pylab as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "from utilities.data_loader import load_imbie, load_mouginot, load_grace, load_ismip6\n",
    "from utilities.helper import hist_start, hist_end, proj_start, proj_end, secpera\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-danger",
   "metadata": {},
   "source": [
    "## Plotting helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 8\n",
    "lw = 0.65\n",
    "aspect_ratio = 0.35\n",
    "markersize = 2\n",
    "\n",
    "params = {\n",
    "    \"axes.linewidth\": 0.25,\n",
    "    \"lines.linewidth\": lw,\n",
    "    \"axes.labelsize\": fontsize,\n",
    "    \"font.size\": fontsize,\n",
    "    \"xtick.direction\": \"in\",\n",
    "    \"xtick.labelsize\": fontsize,\n",
    "    \"xtick.major.size\": 2.5,\n",
    "    \"xtick.major.width\": 0.25,\n",
    "    \"ytick.direction\": \"in\",\n",
    "    \"ytick.labelsize\": fontsize,\n",
    "    \"ytick.major.size\": 2.5,\n",
    "    \"ytick.major.width\": 0.25,\n",
    "    \"legend.fontsize\": fontsize,\n",
    "    \"lines.markersize\": markersize,\n",
    "    \"font.size\": fontsize,\n",
    "}\n",
    "\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "\n",
    "grace_signal_lw = 0.75\n",
    "mouginot_signal_lw = 0.75\n",
    "imbie_signal_lw = 0.75\n",
    "simulated_signal_lw = 0.15\n",
    "grace_signal_color = \"#084594\"\n",
    "grace_sigma_color = \"#9ecae1\"\n",
    "mouginot_signal_color = \"#a63603\"\n",
    "mouginot_sigma_color = \"#fdbe85\"\n",
    "imbie_signal_color = \"#005a32\"\n",
    "imbie_sigma_color = \"#a1d99b\"\n",
    "simulated_signal_color = \"0.7\"\n",
    "\n",
    "gt2cmSLE = 1.0 / 362.5 / 10.0\n",
    "\n",
    "rcp_list = [26, 85]\n",
    "rcp_dict = {26: \"RCP 2.6\", 45: \"RCP 4.5\", 85: \"RCP 8.5\"}\n",
    "rcp_col_dict = {85: \"#990002\", 45: \"#5492CD\", 26: \"#003466\"}\n",
    "rcp_shade_col_dict = {85: \"#F4A582\", 45: \"#92C5DE\", 26: \"#4393C3\"}\n",
    "model_ls_dict = {\"Model Uncertainty (ISMIP6)\": \"solid\", \"Parametric Uncertainty (AS19)\": \"dashed\"}\n",
    "\n",
    "\n",
    "def set_size(w, h, ax=None):\n",
    "    \"\"\" w, h: width, height in inches \"\"\"\n",
    "\n",
    "    if not ax:\n",
    "        ax = plt.gca()\n",
    "    l = ax.figure.subplotpars.left\n",
    "    r = ax.figure.subplotpars.right\n",
    "    t = ax.figure.subplotpars.top\n",
    "    b = ax.figure.subplotpars.bottom\n",
    "    figw = float(w) / (r - l)\n",
    "    figh = float(h) / (t - b)\n",
    "    ax.figure.set_size_inches(figw, figh)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-bhutan",
   "metadata": {},
   "source": [
    "## Load ISMIP6 Greenland projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-customs",
   "metadata": {},
   "outputs": [],
   "source": [
    "ismip6 = load_ismip6()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-restoration",
   "metadata": {},
   "source": [
    "## ISMIP6 in numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-method",
   "metadata": {},
   "outputs": [],
   "source": [
    "ng = len(ismip6.groupby(by=\"Group\").mean())\n",
    "nm = len(ismip6.groupby(by=\"Model\").mean())\n",
    "ne = len(ismip6.groupby(by=\"Exp\").mean())\n",
    "\n",
    "print(f\"Number of modeling groups participated: {ng}\")\n",
    "print(f\"Number of ice sheet model configurations used: {nm}\")\n",
    "print(f\"Number of experiments: {ne}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-kenya",
   "metadata": {},
   "source": [
    "## Load Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-delivery",
   "metadata": {},
   "outputs": [],
   "source": [
    "grace = load_grace()\n",
    "mou19 = load_mouginot()\n",
    "imbie = load_imbie()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-filename",
   "metadata": {},
   "source": [
    "## Plot function to reproduce Figure 1 in Aschwanden et al (2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-emphasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_historical(out_filename, df, grace, mou19, imbie):\n",
    "    \"\"\"\n",
    "    Plot historical simulations and observations.\n",
    "    \"\"\"\n",
    "\n",
    "    def plot_signal(g):\n",
    "        m_df = g[-1]\n",
    "        x = m_df[\"Year\"]\n",
    "        y = m_df[\"Cumulative ice sheet mass change (Gt)\"]\n",
    "\n",
    "        return ax.plot(x, y, color=simulated_signal_color, linewidth=simulated_signal_lw)\n",
    "\n",
    "    xmin = 2000\n",
    "    xmax = 2025\n",
    "    ymin = -3000\n",
    "    ymax = 4000\n",
    "\n",
    "    fig = plt.figure(num=\"historical\", clear=True)\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    \n",
    "    [plot_signal(g) for g in df.groupby(by=[\"Group\", \"Model\", \"Exp\"])]\n",
    "\n",
    "    ismip6_mean = df.groupby(by=\"Year\").mean()\n",
    "    ismip6_std = df.groupby(by=\"Year\").std()\n",
    "    ismip6_low = df.groupby(by=\"Year\").quantile(0.05)\n",
    "    ismip6_high = df.groupby(by=\"Year\").quantile(0.95)\n",
    "\n",
    "\n",
    "    ismip6_ci = ax.fill_between(\n",
    "        ismip6_mean.index,\n",
    "        ismip6_low[\"Cumulative ice sheet mass change (Gt)\"],\n",
    "        ismip6_high[\"Cumulative ice sheet mass change (Gt)\"],\n",
    "        color=\"0.0\",\n",
    "        alpha=0.30,\n",
    "        linewidth=0.0,\n",
    "        zorder=10,\n",
    "        label=\"Simulated (ISMIP6) 90% c.i.\"\n",
    "    )\n",
    "\n",
    "\n",
    "    # Plot GRACE\n",
    "    ax.fill_between(\n",
    "        mou19[\"Year\"],\n",
    "        (1 - 0.057) * mou19[\"Cumulative ice sheet mass change (Gt)\"],\n",
    "        (1 + 0.057) * mou19[\"Cumulative ice sheet mass change (Gt)\"],\n",
    "        color=mouginot_sigma_color,\n",
    "        alpha=0.5,\n",
    "        linewidth=0,\n",
    "    )\n",
    "    mou19_line = ax.plot(\n",
    "        mou19[\"Year\"],\n",
    "        mou19[\"Cumulative ice sheet mass change (Gt)\"],\n",
    "        \"-\",\n",
    "        color=mouginot_signal_color,\n",
    "        linewidth=mouginot_signal_lw,\n",
    "        label=\"Observed (Mouginot)\",\n",
    "    )\n",
    "\n",
    "    ax.fill_between(\n",
    "        imbie[\"Year\"],\n",
    "        imbie[\"Cumulative ice sheet mass change (Gt)\"]\n",
    "        - 1 * imbie[\"Cumulative ice sheet mass change uncertainty (Gt)\"],\n",
    "        imbie[\"Cumulative ice sheet mass change (Gt)\"]\n",
    "        + 1 * imbie[\"Cumulative ice sheet mass change uncertainty (Gt)\"],\n",
    "        color=imbie_sigma_color,\n",
    "        alpha=0.5,\n",
    "        linewidth=0,\n",
    "    )\n",
    "    imbie_line = ax.plot(\n",
    "        imbie[\"Year\"],\n",
    "        imbie[\"Cumulative ice sheet mass change (Gt)\"],\n",
    "        \"-\",\n",
    "        color=imbie_signal_color,\n",
    "        linewidth=imbie_signal_lw,\n",
    "        label=\"Observed (IMBIE)\",\n",
    "    )\n",
    "\n",
    "    ax.fill_between(\n",
    "        grace[\"Year\"],\n",
    "        grace[\"Cumulative ice sheet mass change (Gt)\"]\n",
    "        - 1 * grace[\"Cumulative ice sheet mass change uncertainty (Gt)\"],\n",
    "        grace[\"Cumulative ice sheet mass change (Gt)\"]\n",
    "        + 1 * grace[\"Cumulative ice sheet mass change uncertainty (Gt)\"],\n",
    "        color=grace_sigma_color,\n",
    "        alpha=0.5,\n",
    "        linewidth=0,\n",
    "    )\n",
    "    grace_line = ax.plot(\n",
    "        grace[\"Year\"],\n",
    "        grace[\"Cumulative ice sheet mass change (Gt)\"],\n",
    "        \"-\",\n",
    "        color=grace_signal_color,\n",
    "        linewidth=grace_signal_lw,\n",
    "        label=\"Observed (GRACE)\",\n",
    "    )\n",
    "    ax.axvline(proj_start, color=\"k\", linestyle=\"dashed\", linewidth=grace_signal_lw)\n",
    "    ax.axhline(0, color=\"k\", linestyle=\"dotted\", linewidth=grace_signal_lw)\n",
    "    ax.text(2014.75, 3000, \"Historical Period\", ha=\"right\")\n",
    "    ax.text(2015.25, 3000, \"Projection Period\", ha=\"left\")\n",
    "\n",
    "    model_line = mlines.Line2D([], [], color=simulated_signal_color, linewidth=simulated_signal_lw, label=\"Simulated (ISMIP6)\")\n",
    "\n",
    "    legend = ax.legend(handles=[grace_line[0], mou19_line[0], imbie_line[0], model_line, ismip6_ci], loc=\"lower left\")\n",
    "    legend.get_frame().set_linewidth(0.0)\n",
    "    legend.get_frame().set_alpha(0.0)\n",
    "\n",
    "    ax.set_xlabel(\"Year\")\n",
    "    ax.set_ylabel(f\"Cumulative mass change\\nsince {proj_start} (Gt)\")\n",
    "\n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "    ax_sle = ax.twinx()\n",
    "    ax_sle.set_ylabel(f\"Contribution to sea-level \\nsince {proj_start} (cm SLE)\")\n",
    "    ax_sle.set_ylim(-ymin * gt2cmSLE, -ymax * gt2cmSLE)\n",
    "\n",
    "    set_size(5, 2.5)\n",
    "\n",
    "    fig.savefig(out_filename, bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-liberty",
   "metadata": {},
   "source": [
    "## Plot the historical simulations along side observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-france",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_filename = \"GRIS_historical.pdf\"\n",
    "plot_historical(historical_filename, ismip6, grace, mou19, imbie)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-baghdad",
   "metadata": {},
   "source": [
    "Unfortunately, most simulations underestimate recent (2008--2020) mass loss. Indeed, the observed record of mass loss lies beyond the 95th percentile of the ISMIP6 experiments. Underestimating recent mass loss likely translates into underestimating mass loss at 2100 as well.  That observations and the ensemble are disjoint implies that model uncertainty is underestimated both now and in the future. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excess-manhattan",
   "metadata": {},
   "source": [
    "## Comparison between model and parametric uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-fluid",
   "metadata": {},
   "source": [
    "Let us now compare model uncertainty and parametric uncertainty. Here we will use the 500 member ensemble of Aschwanden et al. (2019) [AS19]. We start by loading the AS19 data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "as19_norm = pd.read_csv(\"as19/aschwanden_et_al_2019_les_2015_norm.csv.gz\")\n",
    "as19_norm[\"SLE (cm)\"] = -as19_norm[\"Mass (Gt)\"] / 362.5 / 10\n",
    "as19_norm = as19_norm.astype({\"RCP\": int, \"Experiment\": int})\n",
    "\n",
    "samples_file = \"lhs_samples/lhs_samples_500.csv\"\n",
    "samples = pd.read_csv(samples_file).rename(columns={\"id\": \"Experiment\"})\n",
    "\n",
    "as19_norm = pd.merge(as19_norm, samples, on=\"Experiment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-producer",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Inter-quartile range (IQR):\\n\\n\")\n",
    "\n",
    "as19_2100 = as19_norm[as19_norm[\"Year\"] == 2100]\n",
    "ismip6_2100 = ismip6[ismip6[\"Year\"] == 2100]\n",
    "model_df_dict = {\"Model Uncertainty (ISMIP6)\": ismip6_2100, \"Parametric Uncertainty (AS19)\": as19_2100}\n",
    "\n",
    "fig = plt.figure(num=\"kde\", clear=True)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "for l, df in model_df_dict.items():\n",
    "    for rcp in rcp_list:\n",
    "        s_df = df[df[\"RCP\"] == rcp]\n",
    "        color = rcp_col_dict[rcp]\n",
    "        sns.kdeplot(data=s_df, x=\"SLE (cm)\", color=color, ls=model_ls_dict[l], ax=ax)\n",
    "        m_q = s_df[\"SLE (cm)\"].quantile(0.75) - s_df[\"SLE (cm)\"].quantile(0.25)\n",
    "        m_q = np.round(m_q, 1)\n",
    "        print(f\"  - {l} {rcp_dict[rcp]} IQR= {m_q:.1f} cm SLE\")\n",
    "\n",
    "lr = [mlines.Line2D([], [], color=rcp_col_dict[rcp], label=f\"RCP {rcp}\") for rcp in rcp_list]\n",
    "lm = [mlines.Line2D([], [], color=\"k\", linestyle=v, label=k) for k, v in model_ls_dict.items()]\n",
    "ax.set_title(\"Model vs parametric uncertainty at 2100\")\n",
    "legend = ax.legend(handles=lr + lm)\n",
    "legend.get_frame().set_linewidth(0.0)\n",
    "legend.get_frame().set_alpha(0.0)\n",
    "set_size(3.2, 1.8)\n",
    "fig.savefig(\"model_vs_parametric_uncerainty_pdf.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d69f96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ismip6_ant_to_csv(basedir, ismip6_filename):\n",
    "    # Now read model output from each of the ISMIP6 files. The information we\n",
    "    # need is in the file names, not the metadate so this is no fun.\n",
    "    # Approach is to read each dataset into a dataframe, then concatenate all\n",
    "    #   dataframes into one Arch dataframe that contains all model runs.\n",
    "    # Resulting dataframe consists of both historical and projected changes\n",
    "\n",
    "    ctrl_files = []\n",
    "    for path in Path(basedir).rglob(\"*_mm_*_ctrl_proj.nc\"):\n",
    "        ctrl_files.append(path)\n",
    "\n",
    "    hist_files = []\n",
    "    for path in Path(basedir).rglob(\"*_mm_*_historical.nc\"):\n",
    "        hist_files.append(path)\n",
    "\n",
    "    dfs = []\n",
    "    for path in Path(basedir).rglob(\"*_mm_cr_*.nc\"):\n",
    "        # Experiment\n",
    "        nc = NC(path)\n",
    "        exp_sle = nc.variables[\"sle\"][:]\n",
    "        # For comparison with GRACE, we use grounded ice mass, converted to Gt\n",
    "        exp_mass = nc.variables[\"limgr\"][:] / 1e12\n",
    "        exp_smb = nc.variables[\"smb\"][:] / 1e12 * secpera\n",
    "\n",
    "        f = path.name.split(f\"scalars_mm_cr_GIS_\")[-1].split(\".nc\")[0].split(\"_\")\n",
    "        # This is ugly, because of \"ITLS_PIK\"\n",
    "        if len(f) == 3:\n",
    "            group, model, exp = f\n",
    "        else:\n",
    "            g1, g2, model, exp = f\n",
    "            group = f\"{g1}_{g2}\"\n",
    "\n",
    "        if exp in [\"exp07\"]:\n",
    "            rcp = 26\n",
    "        else:\n",
    "            rcp = 85\n",
    "        # Find the coressponding CTRL Historical simulations\n",
    "        ctrl_file = [m for m in ctrl_files if (f\"{group}_{model}\" in m.name)][0]\n",
    "        hist_file = [m for m in hist_files if (f\"{group}_{model}\" in m.name)][0]\n",
    "\n",
    "        # The last entry of the historical and the first entry of the projection are the same\n",
    "\n",
    "        # Projection\n",
    "        nc_ctrl = NC(ctrl_file)\n",
    "        ctrl_sle = nc_ctrl.variables[\"sle\"][:]\n",
    "        ctrl_mass = nc_ctrl.variables[\"limgr\"][:] / 1e12\n",
    "        ctrl_smb = nc_ctrl.variables[\"smb\"][:] / 1e12 * secpera\n",
    "\n",
    "        # Historical\n",
    "        nc_hist = NC(hist_file)\n",
    "        hist_sle = nc_hist.variables[\"sle\"][:-1] - nc_hist.variables[\"sle\"][-1]\n",
    "        hist_mass = (nc_hist.variables[\"limgr\"][:-1] - nc_hist.variables[\"limgr\"][-1]) / 1e12\n",
    "        hist_smb = nc_hist.variables[\"smb\"][:-1] / 1e12 * secpera\n",
    "\n",
    "        # Per email with Heiko on Nov. 13, 2020, stick with just the exp projections alone, without adding back the ctrl projections\n",
    "        \"\"\"\n",
    "        from Heiko:\n",
    "        \"The solution that we chose for ISMIP6 is therefore to remove the ctrl_proj from the projections\n",
    "        and communicate the numbers as such, i.e. SL contribution for additional forcing after 2014. \n",
    "        In our (strong) opinion, the results should never be communicated uncorrected.\"\n",
    "        \n",
    "        Also, point of reference from Goelzer et al., 2020, the ctrl simulations represent mass change\n",
    "        with the SMB fixed to 1960-1989 levels (no anomaly in SMB) and no change in ice sheet mask.\n",
    "        So ctrl after the historical spinup represents an abrupt return to an earlier SMB forcing in 2015.\n",
    "        \"\"\"\n",
    "\n",
    "        proj_sle = exp_sle\n",
    "        proj_mass = exp_mass\n",
    "        proj_smb = exp_smb\n",
    "\n",
    "        # Historical simulations start at different years since initialization was left\n",
    "        # up to the modelers\n",
    "        hist_time = -np.arange(len(hist_sle))[::-1] + hist_end\n",
    "\n",
    "        # Let's add the data to the main DataFrame\n",
    "        m_time = np.hstack((hist_time, proj_time))\n",
    "        m_sle = -np.hstack((hist_sle, proj_sle)) * 100\n",
    "        m_sle -= np.interp(proj_start, m_time, m_sle)\n",
    "        m_mass = np.hstack((hist_mass, proj_mass))\n",
    "        m_smb = np.cumsum(np.hstack((hist_smb, proj_smb)))\n",
    "        m_smb -= np.interp(proj_start, m_time, m_smb)\n",
    "        m_d = m_mass - m_smb\n",
    "        m_mass_rate = np.gradient(np.hstack((hist_mass, proj_mass)))\n",
    "        m_smb_rate = np.hstack((hist_smb, proj_smb))\n",
    "        m_d_rate = m_mass_rate - m_smb_rate\n",
    "        m_mass -= np.interp(proj_start, m_time, m_mass)\n",
    "\n",
    "        n = len(m_time)\n",
    "        dfs.append(\n",
    "            pd.DataFrame(\n",
    "                data=np.hstack(\n",
    "                    [\n",
    "                        m_time.reshape(-1, 1),\n",
    "                        m_sle.reshape(-1, 1),\n",
    "                        m_mass.reshape(-1, 1),\n",
    "                        m_smb.reshape(-1, 1),\n",
    "                        m_d.reshape(-1, 1),\n",
    "                        m_mass_rate.reshape(-1, 1),\n",
    "                        m_smb_rate.reshape(-1, 1),\n",
    "                        m_d_rate.reshape(-1, 1),\n",
    "                        np.repeat(group, n).reshape(-1, 1),\n",
    "                        np.repeat(model, n).reshape(-1, 1),\n",
    "                        np.repeat(exp, n).reshape(-1, 1),\n",
    "                        np.repeat(rcp, n).reshape(-1, 1),\n",
    "                    ]\n",
    "                ),\n",
    "                columns=[\n",
    "                    \"Year\",\n",
    "                    \"SLE (cm)\",\n",
    "                    \"Cumulative ice sheet mass change (Gt)\",\n",
    "                    \"Cumulative surface mass balance anomaly (Gt)\",\n",
    "                    \"Cumulative ice dynamics anomaly (Gt)\",\n",
    "                    \"Rate of ice sheet mass change (Gt/yr)\",\n",
    "                    \"Rate of surface mass balance anomaly (Gt/yr)\",\n",
    "                    \"Rate of ice dynamics anomaly (Gt/yr)\",\n",
    "                    \"Group\",\n",
    "                    \"Model\",\n",
    "                    \"Exp\",\n",
    "                    \"RCP\",\n",
    "                ],\n",
    "            )\n",
    "        )\n",
    "        # End of working with each model run individually (the path for-loop)\n",
    "\n",
    "    # Concatenate all DataFrames and convert object types\n",
    "    df = pd.concat(dfs)\n",
    "    df = df.astype(\n",
    "        {\n",
    "            \"Year\": float,\n",
    "            \"SLE (cm)\": float,\n",
    "            \"Cumulative ice sheet mass change (Gt)\": float,\n",
    "            \"Cumulative surface mass balance anomaly (Gt)\": float,\n",
    "            \"Cumulative ice dynamics anomaly (Gt)\": float,\n",
    "            \"Rate of ice sheet mass change (Gt/yr)\": float,\n",
    "            \"Rate of surface mass balance anomaly (Gt/yr)\": float,\n",
    "            \"Rate of ice dynamics anomaly (Gt/yr)\": float,\n",
    "            \"Model\": str,\n",
    "            \"Exp\": str,\n",
    "            \"RCP\": str,\n",
    "        }\n",
    "    )\n",
    "    df.to_csv(ismip6_filename, compression=\"gzip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfad8fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ismip6_ant():\n",
    "    outpath = \".\"\n",
    "    v_dir = \"ComputedScalarsPaper\"\n",
    "    url = f\"https://zenodo.org/record/3940766/files/{v_dir}.zip\"\n",
    "\n",
    "    ismip6_filename = \"ismip6_ant_ctrl_removed.csv.gz\"\n",
    "    if os.path.isfile(ismip6_filename):\n",
    "        df = pd.read_csv(ismip6_filename)\n",
    "    else:\n",
    "        print(f\"{ismip6_filename} not found locally. Downloading the ISMIP6 archive.\")\n",
    "        if not os.path.isfile(f\"{v_dir}.zip\"):\n",
    "            with urlopen(url) as zipresp:\n",
    "                with ZipFile(BytesIO(zipresp.read())) as zfile:\n",
    "                    zfile.extractall(outpath)\n",
    "        print(\"   ...and converting to CSV\")\n",
    "        ismip6_to_csv(v_dir, ismip6_filename)\n",
    "        df = pd.read_csv(ismip6_filename)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8062786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ismip6_ant_ctrl_removed.csv.gz not found locally. Downloading the ISMIP6 archive.\n",
      "   ...and converting to CSV\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0cefda08a113>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_ismip6_ant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-50b7ba76a958>\u001b[0m in \u001b[0;36mload_ismip6_ant\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mzfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"   ...and converting to CSV\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mismip6_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mismip6_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mismip6_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-b2b578a70785>\u001b[0m in \u001b[0;36mismip6_to_csv\u001b[0;34m(basedir, ismip6_filename)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;31m# Concatenate all DataFrames and convert object types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m     df = df.astype(\n\u001b[1;32m    128\u001b[0m         {\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \"\"\"\n\u001b[0;32m--> 285\u001b[0;31m     op = _Concatenator(\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "ant = load_ismip6_ant()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d694597b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
